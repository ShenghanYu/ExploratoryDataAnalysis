plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
# Multiple Linear Regression
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
# Multiple Linear Regression
lm.fit=lm(medv~lstat+age,data=Boston)
summary(lm.fit)
## regress on all variables in the data set
lm.fit=lm(medv~.,data=Boston)
summary(lm.fit)
library(car)
## compute the variance inflation factor as a measure of multicollinearity
vif(lm.fit)
lm.fit1=lm(medv~.-age,data=Boston)
summary(lm.fit1)
lm.fit1=update(lm.fit, ~.-age)
# Interaction Terms
summary(lm(medv~lstat*age,data=Boston))
# Non-linear Transformations of the Predictors
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
lm.fit=lm(medv~lstat+age,data=Boston)
summary(lm.fit)
## regress on all variables in the data set
lm.fit=lm(medv~.,data=Boston)
summary(lm.fit)
library(car)
## compute the variance inflation factor as a measure of multicollinearity
library(car)
install.packages("car")
libray(car)
library(car)
library(car)
## compute the variance inflation factor as a measure of multicollinearity
vif(lm.fit)
lm.fit1=lm(medv~.-age,data=Boston)
summary(lm.fit1)
lm.fit1=update(lm.fit, ~.-age)
# Interaction Terms
summary(lm(medv~lstat*age,data=Boston))
# Non-linear Transformations of the Predictors
lm.fit2=lm(medv~lstat+I(lstat^2))
summary(lm.fit2)
lm.fit=lm(medv~lstat)
## comparing the polynomial to the linear fit
anova(lm.fit,lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit2)
## fitting a fifth degree ploynomial model
lm.fit5=lm(medv~poly(lstat,5))
summary(lm.fit5)
summary(lm(medv~log(rm),data=Boston))
# Qualitative Predictors
fix(Carseats)
names(Carseats)
lm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)
summary(lm.fit)
attach(Carseats)
contrasts(ShelveLoc)
sudo apt-get install git-core
library(dplyr)
library(dplyr)
library(RSQLite)
install.packages("DBI")
getwd()
library(RSQLite)
install.packages("RSQLite")
View(female)
View(lawf)
View(lawf)
library(dplyr)
library(RSQLite)
#Set up connection to the SQLite database
connection <- dbConnect(RSQLite::SQLite(), dbname = "clinton.sqlite")
#Print all tables
print("Tables")
all_tables <-  dbListTables(connection)
print(all_tables)
library(stats)
library(dplyr)
library(RSQLite)
library(lubridate)
library(ggplot2)
#Set up connection to the SQLite database
connection <- dbConnect(RSQLite::SQLite(), dbname = "clinton.sqlite")
#Print all tables
print("Tables")
all_tables <-  dbListTables(connection)
print(all_tables)
#Print information about 'docs' table
docs <- dbGetQuery(connection, sprintf("SELECT * FROM %s", "docs"))
print("Column Name")
print(colnames(docs))
print(sprintf("Number of Rows: %d", nrow(docs)))
#parsing date
for (i in 1:nrow(docs)) {
arrive <- ymd_hms(docs$date, tz = "Pacific/Auckland")
time <- hour(arrive)
time <-time[complete.cases(time)]
date <- as.Date(as.POSIXct(strptime(docs$date, "%Y-%m-%d %H:%M:%S")))
date[complete.cases(date)]
date <-date[complete.cases(date)]
stripped_date = data.frame(date, time)
}
#Clean up connection to the database
dbDisconnect(connection)
library(dplyr)
library(RSQLite)
install.packages("markdown")
library(markdown)
rmarkdown::render
load("~/Dropbox/Fall 2015/Stat communication/sessions/11b/webscraping_in.md.txt")
rmarkdown::render(./webscraping_in.md)
rmarkdown::render(./webscraping_in.md)
webpage <- html("http://www.reed.edu/ir/geographic_states.html")
library(rvest)
install.packages("rvest")
library(rvest)
install.packages("xml2")
library(xml2)
library(rvest)
library(dplyr)
library(stats)
library(base)
library(dplyr)
webpage <- html("http://www.reed.edu/ir/geographic_states.html")
help("Deprecated")
webpage <- read_html("http://www.reed.edu/ir/geographic_states.html")
state <- webpage %>% html_nodes("table") %>% .[[1]] %>% html_table()
View(state)
head(state)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie <- read_html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
movie <- read_html("http://www.imdb.com/name/nm0001618/?ref_=nv_sr_1")
list_of_movies %>%
html_nodes("#filmo-head-actor") %>%
html_text()
Acotr <- read_html("http://www.imdb.com/name/nm0001618/?ref_=nv_sr_1")
list_of_movies %>%
html_nodes("#filmo-head-actor") %>%
html_text()
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
lego_movie %>%
html_nodes("table") %>%
.[[3]] %>%
html_table()
html_nodes("#boardsTeaser") %>%
.[[3]] %>%
html_table()
table
table
html_nodes("table") %>%
.[[3]] %>%
html_table()
lego_movie %>%
html_nodes("table") %>%
.[[3]] %>%
html_table()
lego_movie %>%
html_nodes("#boardsTeaser") %>%
.[[3]] %>%
html_table()
actor <- html("http://www.imdb.com/name/nm0001618/?ref_=nv_sr_1")
actor <- read_html("http://www.imdb.com/name/nm0001618/?ref_=nv_sr_1")
movie %>%
html_nodes(".article") %>%
.[[3]] %>%
html_table()
url <- "http://www.tripadvisor.com/Hotel_Review-g37209-d1762915-Reviews-JW_Marriott_Indianapolis-Indianapolis_Indiana.html"
reviews <- url %>%
read_html() %>%
html_nodes("#REVIEWS .innerBubble")
id <- reviews %>%
html_node(".quote a") %>%
html_attr("id")
quote <- reviews %>%
html_node(".quote span") %>%
html_text()
rating <- reviews %>%
html_node(".rating .rating_s_fill") %>%
html_attr("alt") %>%
gsub(" of 5 stars", "", .) %>%
as.integer()
date <- reviews %>%
html_node(".rating .ratingDate") %>%
html_attr("title") %>%
strptime("%b %d, %Y") %>%
as.POSIXct()
review <- reviews %>%
html_node(".entry .partial_entry") %>%
html_text()
data.frame(id, quote, rating, date, review, stringsAsFactors = FALSE) %>% View()
library(twitteR)
install.packages("twitteR")
library(twitteR)
library(dplyr)
library(twitteR)
library(lubridate)
library(RJSONIO)
library(ggplot2)
library(dismo)
install.packages("dismo")
library(dismo)
library(sp)
library(raster)
library(dismo)
library(maps)
install.packages("maps")
library(maps)
searchTerms<-c("chemical weapons", "cw", "opcw")
names(searchTerms)<-searchTerms
searchTerms<-c("chemical weapons", "cw", "opcw")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=1000)
})
})
searchTerms<-c("flu", "cold", "nausea", "vomiting", "headache")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=1000)
})
searchTwitter("#beer", n=100)
consumerKey = "TnhFkCkWw5XiRjaaU6MVFJXrb"   # from your app name
consumerSecret = "8T2gfZ7hpCRAYcBQbkfURnyT3ylaHEa8BsO2akLz6gll6kN2OM"
accessToken = "377053028-LZYBzp2rcwn3sG103AVVdUvWHYrOBHLhNPP2wq5S"
accessSecret = "eFD67fq59GaltQj45I5F5eT8wEEdlCxEG3bRE3qod8ZVo"
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
searchTwitter("#beer", n=100)
searchTerms<-c("flu", "cold", "nausea", "vomiting", "headache")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=1000)
})
flu
print flu
print "flu
searchTwitter("#beer", n=100)
library(sp)
library(raster)
library(twitteR)
library(lubridate)
library(RJSONIO)
library(ggplot2)
library(dismo)
library(maps)
consumerKey = "TnhFkCkWw5XiRjaaU6MVFJXrb"   # from your app name
consumerSecret = "8T2gfZ7hpCRAYcBQbkfURnyT3ylaHEa8BsO2akLz6gll6kN2OM"
accessToken = "377053028-LZYBzp2rcwn3sG103AVVdUvWHYrOBHLhNPP2wq5S"
accessSecret = "eFD67fq59GaltQj45I5F5eT8wEEdlCxEG3bRE3qod8ZVo"
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
searchTwitter("#beer", n=100)
searchTerms<-c("flu")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=10)
})
rate.limit <- getCurRateLimitInfo()
View(rate.limit)
rate.limit[rate.limit$limit != rate.limit$remaining,]
tweetFrames<-lapply(searchResults, twListToDF)
searchTerms<-c("flu")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=10)
})
tweetFrames<-lapply(searchResults, twListToDF)
tweetFrames <- lapply(tweetFrames, function(df){
df$timeStamp <- ymd_hms(as.character(df$created))
return(df)
})
nTweets <- unlist(lapply(tweetFrames, function(df){
nrow(df)
}))
timeElapsed <- unlist(lapply(tweetFrames, function(df){
as.numeric(diff(range(df$timeStamp)), units = "secs")
}))
tweetsPerSec <- nTweets
plot(tweetsPerSec, type="h", frame.plot=FALSE,  xaxt="n")
axis(1, labels=names(tweetsPerSec), at=c(1:5))
flu<-(unclass(tweetFrames$flu$timeStamp)-1356100000)
searchTerms<-c("Chemical Weapon", "chemical weapons", "OPCW", "opcw")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=10)
})
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=1000)
})
searchTerms<-c("Chemical Weapon", "chemical weapons", "OPCW")
names(searchTerms)<-searchTerms
searchResults<-lapply(searchTerms, function(tt){
print(tt)
searchTwitter(searchString=tt, n=1000)
})
tweetFrames<-lapply(searchResults, twListToDF)
tweetFrames <- lapply(tweetFrames, function(df){
df$timeStamp <- ymd_hms(as.character(df$created))
return(df)
})
nTweets <- unlist(lapply(tweetFrames, function(df){
nrow(df)
}))
timeElapsed <- unlist(lapply(tweetFrames, function(df){
as.numeric(diff(range(df$timeStamp)), units = "days")
}))
tweetsPerSec <- nTweets
plot(tweetsPerSec, type="h", frame.plot=FALSE,  xaxt="n")
axis(1, labels=names(tweetsPerSec), at=c(1:5))
flu<-(unclass(tweetFrames$flu$timeStamp)-1356100000)
tweetFrames<-lapply(searchResults, twListToDF)
tweetFrames <- lapply(tweetFrames, function(df){
df$timeStamp <- ymd_hms(as.character(df$created))
return(df)
})
nTweets <- unlist(lapply(tweetFrames, function(df){
nrow(df)
}))
timeElapsed <- unlist(lapply(tweetFrames, function(df){
as.numeric(diff(range(df$timeStamp)), units = "secs")
}))
tweetsPerSec <- nTweets
plot(tweetsPerSec, type="h", frame.plot=FALSE,  xaxt="n")
axis(1, labels=names(tweetsPerSec), at=c(1:5))
axis(1, labels=names(tweetsPerSec))
axis(1, labels=names(tweetsPerSec), at=c(1:3))
CW <-(unclass(tweetFrames$Chemical Weapon$timeStamp)-1356100000)
CW <-(unclass(tweetFrames$ChemicalWeapon$timeStamp)-1356100000)
head(tweetFrames)
colname(tweetFrames)
ColName(tweetFrames)
ColNames(tweetFrames)
colnames(tweetFrames)
CW <-(unclass(tweetFrames$opcw$timeStamp)-1356100000)
CW <-(unclass(tweetFrames$timeStamp)-1356100000)
searchTerm <- "#opcw"
searchResults <- searchTwitter(searchTerm, n = 1000)
searchTerm <- "opcw"
searchResults <- searchTwitter(searchTerm, n = 1000)
tweetFrame <- twListToDF(searchResults)
View(tweetFrame)
userInfo <- lookupUsers(tweetFrame$screenName)
userFrame <- twListToDF(userInfo)
View(userFrame)
locatedUsers <- !is.na(userFrame$location)
locations <- geocode(userFrame$location[locatedUsers])
View(locations)
plot(locations$lon, locations$lat)
p1 <- ggplot(worldMap)
p2 <- p1 + geom_path(aes(x = long, y = lat, group = group),
colour = gray(2/3), lwd = 1/3)
p3 <- p2 + geom_point(data = locations,
aes(x = lon, y = lat),
colour = "RED", alpha = 1/2, size = 1)
print(p3)
library("ggmap")
library(maptools)
library(maps)
install.packages("ggmap")
library("ggmap")
library("geocode")
install.packages("geocodeHERE")
library("geocodeHERE")
library("ggmap")
library(maptools)
install.packages("maptools")
library(maptools)
library(dismo)
library(maps)
p1 <- ggplot(worldMap)
p2 <- p1 + geom_path(aes(x = long, y = lat, group = group),
colour = gray(2/3), lwd = 1/3)
p3 <- p2 + geom_point(data = locations,
aes(x = lon, y = lat),
colour = "RED", alpha = 1/2, size = 1)
print(p3)
consumerKey = "TnhFkCkWw5XiRjaaU6MVFJXrb"   # from your app name
consumerSecret = "8T2gfZ7hpCRAYcBQbkfURnyT3ylaHEa8BsO2akLz6gll6kN2OM"
accessToken = "377053028-LZYBzp2rcwn3sG103AVVdUvWHYrOBHLhNPP2wq5S"
accessSecret = "eFD67fq59GaltQj45I5F5eT8wEEdlCxEG3bRE3qod8ZVo"
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
searchTerm <- "opcw"
searchResults <- searchTwitter(searchTerm, n = 1000)
tweetFrame <- twListToDF(searchResults)
library(stats)
library(base)
library(xml2)
library(rvest)
library(dplyr)
library(stats)
library(base)
library(xml2)
library(rvest)
library(dplyr)
library(sp)
library(raster)
library(twitteR)
library(lubridate)
library(RJSONIO)
library(ggplot2)
library(dismo)
library(maps)
library("geocodeHERE")
library("ggmap")
library(maptools)
a <- matrix(c(1,0,0,0,0,0,0,1/sqrt(2),1/sqrt(2),0,0,0,0,1/sqrt(2),-1/sqrt(2),0,0,0,0,0,0,1/sqrt(2),1/sqrt(2),0,0,0,0,1/sqrt(2),-1/sqrt(2),0,0,0,0,0,0,1), 6,6, byrow=T)
View(a)
b <- matrix(c(-1,0,0,0,0,0,0,0,1/2,0,0,0,0,0,1/2,0,0,0,0,0,0,1/4,0,0,0,0,0,0,0,0,0,0,0,0,0,0.25), 6,6, byrow=T)
c <- matrix(c(1,0,0,0,0,0,0,1/sqrt(2),1/sqrt(2),0,0,0,0,1/sqrt(2),-1/sqrt(2),0,0,0,0,0,0,1/sqrt(2),1/sqrt(2),0,0,0,0,1/sqrt(2),-1/sqrt(2),0,0,0,0,0,0,1), 6,6, byrow=T)
z <- a*b*c
View(z)
View(a)
View(b)
b <- matrix(c(-1,0,0,0,0,0,0,1/2,0,0,0,0,0,0,1/2,0,0,0,0,0,0,1/4,0,0,0,0,0,0,0,0,0,0,0,0,0,0.25), 6,6, byrow=T)
z <- a*b*c
View(z)
View(z)
dim(z)
eigen(z)
eigen(z^3)
file <- "<a href="https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv">https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv</a>"
library(RCurl)
library(bitops)
library(RCurl)
x <- getURL("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
csv_file <- getURL("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
y <- read.csv(text = csv_file)
csv_file_url <- getURL("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
csv_file <- read.csv(text = csv_file)
csv_file <- read.csv(text = csv_file_url)
df <- Filter(function(x)!all(is.na(x)), csv_file)
View(csv_file)
View(df)
csv_file <- read.csv(csv_file_url)
csv_file_url <- getURL("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
csv_file <- read.csv(csv_file_url)
csv_file_url <- getURL("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
csv_file <- read.csv(csv_file_url)
csv_file <- read.csv(url(csv_file_url))
csv_file <- import("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
library(devtools)
install_github("leeper/rio")
library(rio)
csv_file <- import("https://github.com/Amirosimani/ExploratoryDataAnalysis/blob/master/Survey.csv")
View(csv_file)
library(curl)
# Set local work directory
setwd("./ExploratoryDataAnalysis")
setwd("./GitHub/ExploratoryDataAnalysis")
# Installing all the required packages
library(RCurl)   #to read CSV
library(data.table)  #Data table manipulation
needed.libraries <- c("RCurl", "data.table")
library(RCurl)   #to read CSV
library(data.table)  #Data table manipulation
# Read  file from GitHub repo
CSV_url <- getURL("https://raw.githubusercontent.com/Amirosimani/ExploratoryDataAnalysis/master/Survey.csv")
DataFrame <- read.csv(text = CSV_url)
## Tidying the data frame
DataFrame <- Filter(function(x)!all(is.na(x)), DataFrame) #Delete empty columns
colnames(DataFrame) <- c("waitlist","degree","tools",
"R_DataManipulation", "pronoun","editor","R_Graphics",
"R_MultiVariate","Markdown","Matlab_DataManipulation","GitHub") #Rename columns name
# cleaning up text
DataFrame$tools = gsub("\\(formerly docs\\)", "", DataFrame$tools)
DataFrame$tools =  gsub("\\(grep\\)", "", gsub("\\(terminal \\/ command line\\)","", DataFrame$tools))
#splitting programs into a list
tools <- strsplit(as.character(DataFrame$tools),',')
setDT(DataFrame)[, paste0("tools", 1:16) := tstrsplit(tools, ",")]   #Add seperate column for each program
View(DataFrame)
DataFrame$degree <- as.factor(DataFrame$degree)
View(DataFrame)
DataFrame[,col_names] <- lapply(DataFrame[,col_names] , factor)
col_names <- c("degree", "R_DataManipulation","editor","R_Graphics", "R_MultiVariate","Markdown","Matlab_DataManipulation","GitHub")
DataFrame[,col_names] <- lapply(DataFrame[,col_names] , factor)
col_names <- names(DataFrame)
DataFrame[,col_names] <- lapply(DataFrame[,col_names] , factor)
library(ggplot2)
c <- ggplot(DataFrame, aes(DataFrame$waitlist))
c + geom_bar(width=.5)
c <- ggplot(DataFrame, aes(factor(DataFrame$waitlist)))
c + geom_bar(width=.5)
type(DataFrame$waitlist)
summary(DataFrame$waitlist)
summary(DataFrame$degree)
